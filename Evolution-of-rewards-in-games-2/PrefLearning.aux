\relax 
\@writefile{toc}{\contentsline {section}{\tocsection {}{1}{Introduction}}{1}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{2}{Model}}{1}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.1}{Game, payoffs, and utilities}}{1}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2}{Learning}}{1}}
\newlabel{Lrule}{{1}{2}}
\newlabel{logitchoice}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3}{Fecundity}}{2}}
\newlabel{fec}{{3}{2}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{4}{Preference evolution and the set of possible utility functions}}{2}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{5}{Symmetric two-player games}}{3}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.1}{Four-dimensional adaptive dynamics}}{3}}
\newlabel{cES}{{4}{3}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2}{Analysis of the behavioral interactions between the strategies}}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{5.2.1}{Generic analysis of a 2-player interaction}}{3}}
\newlabel{prefMat}{{5}{3}}
\newlabel{dynotwoRM}{{6}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{5.2.2}{Subset of strategies}}{4}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{6}{Continuous action space}}{5}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.1}{Normally distributed actions}}{5}}
\newlabel{upCa}{{8}{5}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.2}{Stochastic approximation}}{6}}
\newlabel{RfExp}{{9}{6}}
\newlabel{RfExp2}{{10}{6}}
\newlabel{RfExp3}{{11}{6}}
\newlabel{RfExpH}{{12}{6}}
\newlabel{RfExpH2}{{13}{6}}
\newlabel{RfExp}{{14}{6}}
\newlabel{meanF}{{15}{7}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.3}{Bounded action space}}{7}}
\newlabel{logitTr}{{16}{7}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.4}{Baseline simple individual decision problem}}{7}}
\newlabel{cIndSim}{{17}{7}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{7}{Tables}}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classification of behavioral outcomes in the discrete action model amongst the 4 strategies considered.}}{8}}
\newlabel{behOut}{{1}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Generic total payoff in the discrete action model amongst the 4 strategies considered.}}{8}}
\newlabel{payOut}{{2}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Total payoff in the 3 different types of games in the discrete action model amongst the 4 strategies considered.}}{9}}
\newlabel{payOut}{{3}{9}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{18.45073pt}
\newlabel{tocindent2}{27.55019pt}
\newlabel{tocindent3}{0pt}
\@writefile{toc}{\contentsline {section}{\tocsection {}{8}{Figures}}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The ten generic behavioral equilibria in a $2\times 2$ game. The two interior equilibria have long expressions that are not shown here.}}{10}}
\newlabel{genBeh}{{1}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The possible outcomes, the 3 different fitness games, and the 4 strategies considered in the discrete action model. A strategy is defined by the outcomes to which it associates a positive or negative utility in the corresponding outcome matrix (top). Cooperation is denoted by $C$ and defection by $D$. In the outcome matrix, the first letter refers to the action of the focal player (row) and the second letter to the action of its opponent (column). For example, the strategy Realistic associates a positive utility to the outcomes that yield positive material payoffs, and negative utility to outcomes yielding negative material payoffs. The strategy Other-regard associates a positive utility to the outcome where both the focal player cooperates ($C,\cdot $) and has a negative utility for outcomes where the focal player defects ($D,\cdot $).}}{11}}
\newlabel{stratDiscrete}{{2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Vector field (gray arrows) and stochastic trajectory (blue line) for the interaction between ``Pareto'' and ``Selfish''. On the $x$-axis is represented the probability that Pareto cooperates ($p_1$), while on the $y$-axis, this is the probability that Selfish cooperates ($p_2$). The stochastic trajectory is started from the center of the state space $(p_1,p_2) = (\frac  {1}{2},\frac  {1}{2})$ and dots on it represent interaction rounds between the players. Circles represent equilibria: a white-filled circle is a source (both associated eigenvalues are positive); a gray-filled circle is a saddle (one positive and one negative associated eigenvalue); a black circle is a sink (both associated eigenvalues are negative).}}{12}}
\newlabel{cS}{{3}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Same as Fig.\nonbreakingspace \G@refundefinedtrue \text  {\normalfont  \bfseries  ??}\GenericWarning  {               }{LaTeX Warning: Reference `cS' on page 12 undefined} but for the interaction between Pareto and Realistic. Here the deterministic mean field equation admits two locally stable equilibria. The two stochastic trajectories of different color correspond to simulation runs that respectively converge to one of the locally stable equilibria.}}{12}}
\newlabel{dspr}{{4}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Same as Fig.\nonbreakingspace \G@refundefinedtrue \text  {\normalfont  \bfseries  ??}\GenericWarning  {               }{LaTeX Warning: Reference `cS' on page 13 undefined} but for the interaction between Realistic and Realistic. The red-filled dot denotes an equilibrium with 0 eigenvalues.}}{13}}
\newlabel{dspr}{{5}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Vector field for the replicator dynamics in the 4-strategy game defined by the competition between Realistic, Other-regard, Manipulator, and Selfish, when the underlying one-shot fitness game is a Prisoner's dilemma.}}{13}}
\newlabel{dspr}{{6}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Continuous learning in a deterministic 1-player game. (A) The function $u_i(a_i)$ to be maximized by the player (eq.\nonbreakingspace \G@refundefinedtrue \text  {\normalfont  \bfseries  ??}\GenericWarning  {               }{LaTeX Warning: Reference `cIndSim' on page 14 undefined}), with $\beta =0.6$. (B) Typical dynamics of the mean action, $m_{i,t+1}$ when the utility function is that in (A).}}{14}}
\newlabel{simIndDyn}{{7}{14}}
